import torch
from transformers import BertForSequenceClassification, AutoTokenizer
import os

os.environ["MECAB_PATH"] = r"C:\Users\ICT-27\Downloads\mecab-ko-msvc-x64\mecab.exe"
# âœ… ëª¨ë¸ íŒŒì¼ ê²½ë¡œ ì„¤ì •
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
model_path = os.path.join(BASE_DIR, "trained_model.pth")  # ëª¨ë¸ íŒŒì¼ëª… ì£¼ì˜!

# âœ… BERT ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°
model_name = "cl-tohoku/bert-base-japanese"  # Jupyterì—ì„œ ì‚¬ìš©í•œ BERT ëª¨ë¸ê³¼ ë™ì¼í•´ì•¼ í•¨!
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = BertForSequenceClassification.from_pretrained(model_name, num_labels=2)  # ê¸ì •/ë¶€ì • 2ê°œ í´ë˜ìŠ¤

# âœ… ëª¨ë¸ ê°€ì¤‘ì¹˜ ë¶ˆëŸ¬ì˜¤ê¸°
if os.path.exists(model_path):
    model.load_state_dict(torch.load(model_path, map_location=torch.device("cpu")))
    model.eval()
    print(f"âœ… BERT ëª¨ë¸ ë¡œë“œ ì„±ê³µ: {model_path}")
else:
    raise FileNotFoundError(f"âŒ ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {model_path}")

# âœ… ê°ì • ë¶„ì„ í•¨ìˆ˜
def predict_sentiment(text):
    inputs = tokenizer(text, return_tensors="pt", truncation=True, padding=True, max_length=128)
    with torch.no_grad():
        outputs = model(**inputs)
        logits = outputs.logits
        predicted_class = torch.argmax(logits, dim=1).item()
    label_mapping = {0: "ë¶€ì •", 1: "ê¸ì •"}
    return label_mapping[predicted_class]

# âœ… í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì½”ë“œ
if __name__ == "__main__":
    test_text = "ã“ã®æ—…è¡Œã¯æœ€é«˜ã§ã—ãŸï¼"
    result = predict_sentiment(test_text)
    print(f"ğŸ“ í…ŒìŠ¤íŠ¸ ë¬¸ì¥: {test_text}")
    print(f"ğŸ¯ ì˜ˆì¸¡ëœ ê°ì •: {result}")  